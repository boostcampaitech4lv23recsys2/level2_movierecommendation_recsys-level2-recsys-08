{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cd73963",
   "metadata": {},
   "source": [
    "# FMM Recbole 구현"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61e884e8",
   "metadata": {},
   "source": [
    "### Recbole 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f451253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0037a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656860e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "\n",
    "from logging import getLogger\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from recbole.model.context_aware_recommender.ffm import FFM\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.utils import init_logger, get_trainer, init_seed, set_color, get_model\n",
    "from recbole.quick_start.quick_start import load_data_and_model\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import ndcg_score, recall_score\n",
    "\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "049a025e",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf1eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/opt/ml/input/data/train/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eeda3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5154471 entries, 0 to 5154470\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   user    int64\n",
      " 1   item    int64\n",
      " 2   time    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 118.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754874f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/opt/ml/input/data/train'\n",
    "year_data = pd.read_csv(os.path.join(data_path, 'years.tsv'), sep='\\t')\n",
    "writer_data = pd.read_csv(os.path.join(data_path, 'writers.tsv'), sep='\\t')\n",
    "title_data = pd.read_csv(os.path.join(data_path, 'titles.tsv'), sep='\\t')\n",
    "genre_data = pd.read_csv(os.path.join(data_path, 'genres.tsv'), sep='\\t')\n",
    "director_data = pd.read_csv(os.path.join(data_path, 'directors.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80736508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(train_df, year_data, on='item', how='left')\n",
    "df_merge = pd.merge(df_merge, writer_data, on='item', how='left')\n",
    "df_merge = pd.merge(df_merge, title_data, on='item', how='left')\n",
    "df_merge = pd.merge(df_merge, genre_data, on='item', how='left')\n",
    "df_merge = pd.merge(df_merge, director_data, on='item', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecfd29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['item'].nunique()\n",
    "df_merge['item'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf5b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.sort_values('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1660352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>writer</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>nm0099541</td>\n",
       "      <td>Planet of the Apes (2001)</td>\n",
       "      <td>Action</td>\n",
       "      <td>nm0000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>11</td>\n",
       "      <td>8907</td>\n",
       "      <td>1230856729</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>nm0769840</td>\n",
       "      <td>Shark Tale (2004)</td>\n",
       "      <td>Children</td>\n",
       "      <td>nm1224299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>11</td>\n",
       "      <td>8907</td>\n",
       "      <td>1230856729</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>nm0769840</td>\n",
       "      <td>Shark Tale (2004)</td>\n",
       "      <td>Children</td>\n",
       "      <td>nm0421776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>11</td>\n",
       "      <td>8907</td>\n",
       "      <td>1230856729</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>nm0769840</td>\n",
       "      <td>Shark Tale (2004)</td>\n",
       "      <td>Children</td>\n",
       "      <td>nm0074426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>11</td>\n",
       "      <td>8907</td>\n",
       "      <td>1230856729</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>nm0769840</td>\n",
       "      <td>Shark Tale (2004)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>nm0421776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  item        time    year     writer                      title  \\\n",
       "0       11  4643  1230782529  2001.0  nm0099541  Planet of the Apes (2001)   \n",
       "3077    11  8907  1230856729  2004.0  nm0769840          Shark Tale (2004)   \n",
       "3076    11  8907  1230856729  2004.0  nm0769840          Shark Tale (2004)   \n",
       "3075    11  8907  1230856729  2004.0  nm0769840          Shark Tale (2004)   \n",
       "3073    11  8907  1230856729  2004.0  nm0769840          Shark Tale (2004)   \n",
       "\n",
       "          genre   director  \n",
       "0        Action  nm0000318  \n",
       "3077   Children  nm1224299  \n",
       "3076   Children  nm0421776  \n",
       "3075   Children  nm0074426  \n",
       "3073  Animation  nm0421776  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaa10731",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_merge[['user', 'item', 'time']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940e39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = df_merge[['user']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b2c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = df_merge[['item', 'year', 'writer', 'title', 'genre', 'director']].drop_duplicates(subset=['item']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd414cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48264331 entries, 0 to 48264330\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   user    int64\n",
      " 1   item    int64\n",
      " 2   time    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b31ea219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_user : 31360\n",
      "n_item : 6807\n"
     ]
    }
   ],
   "source": [
    "userid, itemid = list(set(train_data.user)), list(set(train_data.item))\n",
    "n_user, n_item = len(userid), len(itemid)\n",
    "print(f'n_user : {n_user}')\n",
    "print(f'n_item : {n_item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ffaaddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119145"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(itemid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "043f7e24",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17ee70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d043e6eb",
   "metadata": {},
   "source": [
    "### 데이터 파일 변환\n",
    "\n",
    "기존 데이터 파일을 Recbole 데이터 파일로 변환시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd4f31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid, itemid = sorted(userid), sorted(itemid)\n",
    "n_user, n_item = len(userid), len(itemid)\n",
    "\n",
    "userid_2_index = {v:i for i,v in enumerate(userid)}\n",
    "itemid_2_index = {v:i for i,v in enumerate(itemid)}\n",
    "index_2_userid = {i:v for i,v in enumerate(userid)}\n",
    "index_2_itemid = {i:v for i,v in enumerate(itemid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "921af69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yamldata = \"\"\"\n",
    "field_separator: \"\\t\"\n",
    "USER_ID_FIELD: user_id\n",
    "ITEM_ID_FIELD: item_id\n",
    "TIME_FIELD: timestamp\n",
    "\n",
    "load_col:\n",
    "    inter: [user_id, item_id, timestamp]\n",
    "    user: [user_id]\n",
    "    item: [item_id, year, writer, title, genre, director]\n",
    "\n",
    "train_neg_sample_args:\n",
    "    uniform: 1\n",
    "    \n",
    "eval_args:\n",
    "    split: {'RS': [0.98, 0.01, 0.01]}\n",
    "    group_by: user\n",
    "    order: RO\n",
    "    mode: full\n",
    "metrics: ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
    "topk: 10\n",
    "valid_metric: Recall@10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6b7236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.user = train_data.user.map(userid_2_index)\n",
    "train_data.item = train_data.item.map(itemid_2_index)\n",
    "\n",
    "user_data.user = user_data.user.map(userid_2_index)\n",
    "item_data.item = item_data.item.map(itemid_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd5f3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns=['user_id:token', 'item_id:token', 'timestamp:float']\n",
    "user_data.columns=['user_id:token']\n",
    "item_data.columns=['item_id:token', 'year:token', 'writer:token', 'title:token_seq', 'genre:token', 'director:token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f344922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Complete\n"
     ]
    }
   ],
   "source": [
    "outpath = f\"dataset/train_data\"\n",
    "# outfile = f\"dataset/train_data/train_data.inter\"\n",
    "yamlfile = f\"train_data.yaml\"\n",
    "\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "# sub_train=train.groupby(\"user\").sample(n=10, random_state=SEED)\n",
    "# sub_train.shape\n",
    "\n",
    "# print(\"Processing Start\")\n",
    "# inter_table = []\n",
    "# for user, item, time in zip(train_data.user, train_data.item, train_data.time):\n",
    "#     uid, iid = userid_2_index[user], itemid_2_index[item]\n",
    "#     # tval = int(time.mktime(datetime.datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "#     inter_table.append( [uid, iid, time] )\n",
    "\n",
    "# print(\"Processing Complete\")\n",
    "\n",
    "print(\"Dump Start\")\n",
    "# 데이터 설정 파일 저장\n",
    "with open(yamlfile, \"w\") as f:\n",
    "    f.write(yamldata) \n",
    "\n",
    "# 데이터 파일 저장\n",
    "train_data.to_csv(os.path.join(outpath,\"train_data.inter\"),sep='\\t',index=False)\n",
    "user_data.to_csv(os.path.join(outpath,\"train_data.user\"),sep='\\t',index=False)\n",
    "item_data.to_csv(os.path.join(outpath,\"train_data.item\"),sep='\\t',index=False)\n",
    "# with open(outfile, \"w\") as f:\n",
    "#     # write header\n",
    "#     f.write(\"user_id:token\\titem_id:token\\ttimestamp:float\\n\")\n",
    "#     for row in inter_table:\n",
    "#         f.write(\"\\t\".join([str(x) for x in row])+\"\\n\")\n",
    "\n",
    "print(\"Dump Complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf654e50",
   "metadata": {},
   "source": [
    "### 로거 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "448113f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac5c55e3",
   "metadata": {},
   "source": [
    "### 설정 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c21f27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Dec 20:11    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/train_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 1\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.98, 0.01, 0.01]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'user': ['user_id'], 'item': ['item_id', 'year', 'writer', 'title', 'genre', 'director']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "fields = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configurations initialization\n",
    "config = Config(model='FFM', dataset=\"train_data\", config_file_list=[f'train_data.yaml'])\n",
    "config['epochs'] = 1\n",
    "config['show_progress'] = False\n",
    "config['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "\n",
    "logger.info(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a62100b4",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd284775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Dec 20:16    INFO  train_data\n",
      "The number of users: 31361\n",
      "Average actions of users: 1539.0411670918368\n",
      "The number of items: 6808\n",
      "Average actions of items: 7090.396797414426\n",
      "The number of inters: 48264331\n",
      "The sparsity of the dataset: 77.3943582243111%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director']\n",
      "25 Dec 20:18    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "25 Dec 20:18    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.98, 0.01, 0.01]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# dataset filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7da7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 1509.2573660714286\n",
       "\u001b[1;34mThe number of items\u001b[0m: 6808\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 6953.182165417952\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 47330311\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 77.83182666309105%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 14.891900510204081\n",
       "\u001b[1;34mThe number of items\u001b[0m: 6808\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 75.47026502908855\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 467010\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.78126578061001%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 14.891900510204081\n",
       "\u001b[1;34mThe number of items\u001b[0m: 6808\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 75.05785920925747\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 467010\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.78126578061001%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset\n",
    "valid_data.dataset\n",
    "test_data.dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39da2a0e",
   "metadata": {},
   "source": [
    "### 모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "419bdaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Dec 20:18    INFO  FFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(42034, 10)\n",
      "  )\n",
      "  (token_seq_embedding_table): ModuleList(\n",
      "    (0): Embedding(9166, 10)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(42034, 1)\n",
      "    )\n",
      "    (token_seq_embedding_table): ModuleList(\n",
      "      (0): Embedding(9166, 1)\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (ffm): FieldAwareFactorizationMachine(\n",
      "    (token_embeddings): ModuleList(\n",
      "      (0): Embedding(42034, 10)\n",
      "      (1): Embedding(42034, 10)\n",
      "      (2): Embedding(42034, 10)\n",
      "      (3): Embedding(42034, 10)\n",
      "      (4): Embedding(42034, 10)\n",
      "      (5): Embedding(42034, 10)\n",
      "      (6): Embedding(42034, 10)\n",
      "    )\n",
      "    (token_seq_embeddings): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (3): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (4): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (5): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (6): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "    )\n",
      "    (token_seq_embedding): ModuleList(\n",
      "      (0): Embedding(9166, 10)\n",
      "      (1): Embedding(9166, 10)\n",
      "      (2): Embedding(9166, 10)\n",
      "      (3): Embedding(9166, 10)\n",
      "      (4): Embedding(9166, 10)\n",
      "      (5): Embedding(9166, 10)\n",
      "      (6): Embedding(9166, 10)\n",
      "    )\n",
      "  )\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 4147201\n"
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "model = FFM(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c05bfd1e",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bb1b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Dec 20:34    INFO  epoch 0 training [time: 933.53s, train loss: 9319.8292]\n",
      "25 Dec 20:38    INFO  epoch 0 evaluating [time: 238.06s, valid_score: 0.264200]\n",
      "25 Dec 20:38    INFO  valid result: \n",
      "recall@10 : 0.2642    mrr@10 : 0.5806    ndcg@10 : 0.3612    hit@10 : 0.8577    precision@10 : 0.2857    map@10 : 0.2321\n",
      "25 Dec 20:38    INFO  Saving current: saved/FFM-Dec-25-2022_20-18-51.pth\n"
     ]
    }
   ],
   "source": [
    "# trainer loading and initialization\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data, valid_data, saved=True, show_progress=config['show_progress']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baf0ea34",
   "metadata": {},
   "source": [
    "### 학습 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40d5e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Dec 20:38    INFO  Loading model structure and parameters from saved/FFM-Dec-25-2022_20-18-51.pth\n",
      "25 Dec 20:42    INFO  best valid : OrderedDict([('recall@10', 0.2642), ('mrr@10', 0.5806), ('ndcg@10', 0.3612), ('hit@10', 0.8577), ('precision@10', 0.2857), ('map@10', 0.2321)])\n",
      "25 Dec 20:42    INFO  test result: OrderedDict([('recall@10', 0.2653), ('mrr@10', 0.5785), ('ndcg@10', 0.3611), ('hit@10', 0.8579), ('precision@10', 0.2857), ('map@10', 0.2318)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"best_valid_score\": 0.2642,\n",
      "    \"valid_score_bigger\": true,\n",
      "    \"best_valid_result\": {\n",
      "        \"recall@10\": 0.2642,\n",
      "        \"mrr@10\": 0.5806,\n",
      "        \"ndcg@10\": 0.3612,\n",
      "        \"hit@10\": 0.8577,\n",
      "        \"precision@10\": 0.2857,\n",
      "        \"map@10\": 0.2321\n",
      "    },\n",
      "    \"test_result\": {\n",
      "        \"recall@10\": 0.2653,\n",
      "        \"mrr@10\": 0.5785,\n",
      "        \"ndcg@10\": 0.3611,\n",
      "        \"hit@10\": 0.8579,\n",
      "        \"precision@10\": 0.2857,\n",
      "        \"map@10\": 0.2318\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data, load_best_model=\"True\", show_progress=config['show_progress'])\n",
    "\n",
    "logger.info(set_color('best valid ', 'yellow') + f': {best_valid_result}')\n",
    "logger.info(set_color('test result', 'yellow') + f': {test_result}')\n",
    "\n",
    "result = {\n",
    "    'best_valid_score': best_valid_score,\n",
    "    'valid_score_bigger': config['valid_metric_bigger'],\n",
    "    'best_valid_result': best_valid_result,\n",
    "    'test_result': test_result\n",
    "}\n",
    "\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fefa4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Dec 20:42    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/train_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 1\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.98, 0.01, 0.01]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'user': ['user_id'], 'item': ['item_id', 'year', 'writer', 'title', 'genre', 'director']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "fields = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "25 Dec 20:48    INFO  train_data\n",
      "The number of users: 31361\n",
      "Average actions of users: 1539.0411670918368\n",
      "The number of items: 6808\n",
      "Average actions of items: 7090.396797414426\n",
      "The number of inters: 48264331\n",
      "The sparsity of the dataset: 77.3943582243111%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director']\n",
      "25 Dec 20:50    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "25 Dec 20:50    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.98, 0.01, 0.01]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model_path='saved/FFM-Dec-25-2022_20-18-51.pth'\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d96a06f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b0a3197",
   "metadata": {},
   "source": [
    "#### 전체 item에서 각 사용자가 이미 본 item과 FFM으로 추천하는 100개 item을 제외한 item 중\n",
    "#### random으로 negative sample 50개 추출!\n",
    "\n",
    "-> 그럼 사용자 별로 50개의 negative sample, 전체로는 31360 * 50 개의 negative sample이 만들어진다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a575b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "11        [4643, 8907, 36401, 41571, 56757, 761, 2004, 8...\n",
       "14        [1022, 4921, 40629, 4886, 31658, 364, 4027, 60...\n",
       "18        [1209, 1211, 7034, 7361, 1247, 7234, 1305, 120...\n",
       "25        [919, 2706, 4306, 1291, 1193, 5952, 2683, 288,...\n",
       "31        [8907, 56171, 102125, 32031, 45431, 42738, 472...\n",
       "                                ...                        \n",
       "138473    [1921, 31658, 65261, 3000, 1840, 1, 8507, 8533...\n",
       "138475    [7132, 2936, 3730, 2010, 5177, 923, 3629, 7234...\n",
       "138486    [919, 1917, 2617, 6863, 35836, 1136, 6333, 235...\n",
       "138492    [2571, 3000, 6874, 2859, 1923, 69, 1649, 3677,...\n",
       "138493    [364, 2087, 2078, 1029, 4306, 596, 2018, 588, ...\n",
       "Name: item, Length: 31360, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = df_merge.groupby('user')['item'].unique()\n",
    "before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "745be7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/245 [00:00<?, ?it/s]/opt/conda/envs/movie_rec/lib/python3.10/site-packages/recbole/utils/case_study.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uid_series = torch.tensor(uid_series)\n",
      "Inference:   5%|▌         | 13/245 [00:01<00:18, 12.37it/s]:  11%|█         | 26/245 [00:02<00:17, 12.42it/s]:  16%|█▌        | 39/245 [00:03<00:16, 12.42it/s]:  21%|██        | 52/245 [00:04<00:15, 12.40it/s]:  27%|██▋       | 65/245 [00:05<00:14, 12.37it/s]:  32%|███▏      | 78/245 [00:06<00:13, 12.35it/s]:  37%|███▋      | 91/245 [00:07<00:12, 12.33it/s]:  42%|████▏     | 104/245 [00:08<00:11, 12.30it/s]:  48%|████▊     | 117/245 [00:09<00:10, 12.27it/s]:  53%|█████▎    | 130/245 [00:10<00:09, 12.22it/s]:  58%|█████▊    | 143/245 [00:11<00:08, 12.20it/s]:  64%|██████▎   | 156/245 [00:12<00:07, 12.18it/s]:  69%|██████▉   | 169/245 [00:13<00:06, 12.15it/s]:  74%|███████▍  | 182/245 [00:14<00:05, 12.10it/s]:  80%|███████▉  | 195/245 [00:15<00:04, 12.06it/s]:  85%|████████▍ | 208/245 [00:17<00:03, 12.02it/s]:  90%|█████████ | 221/245 [00:18<00:02, 11.93it/s]:  95%|█████████▌| 233/245 [00:19<00:01, 11.92it/s]: 100%|██████████| 245/245 [00:20<00:00, 11.87it/s]: 100%|██████████| 245/245 [00:20<00:00, 12.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from recbole.utils.case_study import full_sort_topk\n",
    "\n",
    "user_id = config['USER_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "all_user_list = torch.arange(1, len(user_id2token)).view(-1,128)\n",
    "\n",
    "device = config.final_config_dict['device']\n",
    "\n",
    "tbar = tqdm(all_user_list, desc=set_color(f\"Inference\", 'pink'), leave=True, mininterval=1)\n",
    "\n",
    "pred_list = None\n",
    "user_list = []\n",
    "for data in tbar:\n",
    "    batch_pred_list = full_sort_topk(data, model, test_data, 100, device=device)[1]\n",
    "    batch_pred_list = batch_pred_list.clone().detach().cpu().numpy()\n",
    "    if pred_list is None:\n",
    "        pred_list = batch_pred_list\n",
    "        user_list = data.numpy()\n",
    "    else:\n",
    "        pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "        user_list = np.append(\n",
    "            user_list, data.numpy(), axis=0\n",
    "        )\n",
    "tbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd7aff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user별 이미 본 item과 item 추천 결과 하나로 합쳐주기\n",
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    user = int(index_2_userid[user-1])\n",
    "    user_before = df_merge[df_merge['user'] == user]['item'].unique()\n",
    "    list(pred).append(list(user_before))\n",
    "    pred = list(set(pred))\n",
    "    for item in pred:\n",
    "        item = int(index_2_itemid[item-1])\n",
    "        result.append((user, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Create Nagetive instances\")\n",
    "num_negative = 50\n",
    "user_group_dfs = list(pd.DataFrame(result).groupby('user')['item'])\n",
    "first_row = True\n",
    "user_neg_dfs = pd.DataFrame() # 총 유저의 negative sample df\n",
    "\n",
    "# 각 user의 negative sample df를 구하고 총 유저의 negative sample df인 user_neg_dfs 에 concat하는 과정\n",
    "for u, u_items in tqdm(user_group_dfs): # 한 유저와 해당 유저의 item들이 for문을 통해 (모든유저가 똑같이) 반복됨.\n",
    "    u_items = set(u_items) # 해당 유저의 item 중복 제거 <- 위에서 해줬기 때문에 안 해도 되긴 함\n",
    "    i_user_neg_item = np.random.choice(list(set(itemid) - u_items), num_negative, replace=False) # negative sample 생성\n",
    "    # np.random.choice() : Generates a random sample from a given 1-D array\n",
    "\n",
    "    i_user_neg_df = pd.DataFrame({'user': [u]*num_negative, 'item': i_user_neg_item, 'label': [0]*num_negative}) # negative sample df 생성\n",
    "    if first_row == True: # 첫번째 유저일 때만 실행\n",
    "        user_neg_dfs = i_user_neg_df\n",
    "        first_row = False\n",
    "    else:\n",
    "        user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 df에 label 추가 후 negative sample df와 합쳐주기\n",
    "origin_train_df = pd.read_csv('/opt/ml/input/data/train/train_ratings.csv')\n",
    "origin_train_df[\"label\"] = 1\n",
    "p_n_train_df = pd.concat([origin_train_df, user_neg_dfs], axis = 0, sort=False)\n",
    "p_n_train_dff = p_n_train_df.sort_values(by=['user']) # 유저를 기준으로 df 정렬\n",
    "p_n_train_df.reset_index(drop=True, inplace=True) # 인덱스 리셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e37d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference done!\n"
     ]
    }
   ],
   "source": [
    "# negative sample file 제작하기\n",
    "sub = p_n_train_df\n",
    "sub.to_csv(\n",
    "    \"p_n_train_ratings.csv\", index=False\n",
    ")\n",
    "print('done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3d4ebc8f5be3b9760b7b8c89820e25f6cc4c8c3873d1ecd46134e38c918e05a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
