{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cd73963",
   "metadata": {},
   "source": [
    "# FMM Recbole 구현"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61e884e8",
   "metadata": {},
   "source": [
    "### Recbole 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f451253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0037a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "656860e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "\n",
    "from logging import getLogger\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from recbole.model.context_aware_recommender.ffm import FFM\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.utils import init_logger, get_trainer, init_seed, set_color, get_model\n",
    "from recbole.quick_start.quick_start import load_data_and_model\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import ndcg_score, recall_score\n",
    "\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "049a025e",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf1eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/opt/ml/input/data/train/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eeda3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5154471 entries, 0 to 5154470\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   user    int64\n",
      " 1   item    int64\n",
      " 2   time    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 118.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754874f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/opt/ml/input/data/train'\n",
    "year_data = pd.read_csv(os.path.join(data_path, 'years.tsv'), sep='\\t')\n",
    "writer_data = pd.read_csv(os.path.join(data_path, 'writers.tsv'), sep='\\t')\n",
    "title_data = pd.read_csv(os.path.join(data_path, 'titles.tsv'), sep='\\t')\n",
    "genre_data = pd.read_csv(os.path.join(data_path, 'genres.tsv'), sep='\\t')\n",
    "director_data = pd.read_csv(os.path.join(data_path, 'directors.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80736508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(train_df, year_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, writer_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, title_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, genre_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, director_data.drop_duplicates(subset=['item']), on='item', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf5b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.sort_values('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1660352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>writer</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "      <td>2001</td>\n",
       "      <td>nm0099541</td>\n",
       "      <td>Planet of the Apes (2001)</td>\n",
       "      <td>Action</td>\n",
       "      <td>nm0000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026932</th>\n",
       "      <td>11</td>\n",
       "      <td>5952</td>\n",
       "      <td>1230859039</td>\n",
       "      <td>2002</td>\n",
       "      <td>nm0001392</td>\n",
       "      <td>Lord of the Rings: The Two Towers, The (2002)</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>nm0001392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49913</th>\n",
       "      <td>11</td>\n",
       "      <td>7293</td>\n",
       "      <td>1230783500</td>\n",
       "      <td>2004</td>\n",
       "      <td>nm1286500</td>\n",
       "      <td>50 First Dates (2004)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>nm0781842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372760</th>\n",
       "      <td>11</td>\n",
       "      <td>2716</td>\n",
       "      <td>1230788672</td>\n",
       "      <td>1984</td>\n",
       "      <td>nm0000101</td>\n",
       "      <td>Ghostbusters (a.k.a. Ghost Busters) (1984)</td>\n",
       "      <td>Action</td>\n",
       "      <td>nm0718645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372053</th>\n",
       "      <td>11</td>\n",
       "      <td>27728</td>\n",
       "      <td>1230788663</td>\n",
       "      <td>2004</td>\n",
       "      <td>nm0258268</td>\n",
       "      <td>Ghost in the Shell 2: Innocence (a.k.a. Innoce...</td>\n",
       "      <td>Action</td>\n",
       "      <td>nm0651900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user   item        time  year     writer  \\\n",
       "0          11   4643  1230782529  2001  nm0099541   \n",
       "1026932    11   5952  1230859039  2002  nm0001392   \n",
       "49913      11   7293  1230783500  2004  nm1286500   \n",
       "372760     11   2716  1230788672  1984  nm0000101   \n",
       "372053     11  27728  1230788663  2004  nm0258268   \n",
       "\n",
       "                                                     title      genre  \\\n",
       "0                                Planet of the Apes (2001)     Action   \n",
       "1026932      Lord of the Rings: The Two Towers, The (2002)  Adventure   \n",
       "49913                                50 First Dates (2004)     Comedy   \n",
       "372760          Ghostbusters (a.k.a. Ghost Busters) (1984)     Action   \n",
       "372053   Ghost in the Shell 2: Innocence (a.k.a. Innoce...     Action   \n",
       "\n",
       "          director  \n",
       "0        nm0000318  \n",
       "1026932  nm0001392  \n",
       "49913    nm0781842  \n",
       "372760   nm0718645  \n",
       "372053   nm0651900  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa10731",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_merge[['user', 'item', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940e39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = df_merge[['user']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b2c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = df_merge[['item', 'year', 'writer', 'title', 'genre', 'director']].drop_duplicates(subset=['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd414cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4658299 entries, 0 to 3455563\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   user    int64\n",
      " 1   item    int64\n",
      " 2   time    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 142.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31ea219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_user : 31360\n",
      "n_item : 4967\n"
     ]
    }
   ],
   "source": [
    "userid, itemid = list(set(train_data.user)), list(set(train_data.item))\n",
    "n_user, n_item = len(userid), len(itemid)\n",
    "print(f'n_user : {n_user}')\n",
    "print(f'n_item : {n_item}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "043f7e24",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17ee70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d043e6eb",
   "metadata": {},
   "source": [
    "### 데이터 파일 변환\n",
    "\n",
    "기존 데이터 파일을 Recbole 데이터 파일로 변환시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd4f31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid, itemid = sorted(userid), sorted(itemid)\n",
    "n_user, n_item = len(userid), len(itemid)\n",
    "\n",
    "userid_2_index = {v:i for i,v in enumerate(userid)}\n",
    "itemid_2_index = {v:i for i,v in enumerate(itemid)}\n",
    "index_2_userid = {i:v for i,v in enumerate(userid)}\n",
    "index_2_itemid = {i:v for i,v in enumerate(itemid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921af69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yamldata = \"\"\"\n",
    "field_separator: \"\\t\"\n",
    "USER_ID_FIELD: user_id\n",
    "ITEM_ID_FIELD: item_id\n",
    "TIME_FIELD: timestamp\n",
    "\n",
    "load_col:\n",
    "    inter: [user_id, item_id, timestamp]\n",
    "    user: [user_id]\n",
    "    item: [item_id, year, writer, title, genre, director]\n",
    "\n",
    "train_neg_sample_args:\n",
    "    uniform: 1\n",
    "    \n",
    "eval_args:\n",
    "    split: {'RS': [4, 1, 1]}\n",
    "    group_by: user\n",
    "    order: RO\n",
    "    mode: full\n",
    "metrics: ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
    "topk: 10\n",
    "valid_metric: Recall@10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b7236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39833/1297655130.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.user = train_data.user.map(userid_2_index)\n",
      "/tmp/ipykernel_39833/1297655130.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.item = train_data.item.map(itemid_2_index)\n",
      "/tmp/ipykernel_39833/1297655130.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data.user = user_data.user.map(userid_2_index)\n"
     ]
    }
   ],
   "source": [
    "train_data.user = train_data.user.map(userid_2_index)\n",
    "train_data.item = train_data.item.map(itemid_2_index)\n",
    "\n",
    "user_data.user = user_data.user.map(userid_2_index)\n",
    "item_data.item = item_data.item.map(itemid_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd5f3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns=['user_id:token', 'item_id:token', 'timestamp:float']\n",
    "user_data.columns=['user_id:token']\n",
    "item_data.columns=['item_id:token', 'year:float', 'writer:token', 'title:token', 'genre:token', 'director:token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f344922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Complete\n"
     ]
    }
   ],
   "source": [
    "outpath = f\"dataset/train_data\"\n",
    "# outfile = f\"dataset/train_data/train_data.inter\"\n",
    "yamlfile = f\"train_data.yaml\"\n",
    "\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "# sub_train=train.groupby(\"user\").sample(n=10, random_state=SEED)\n",
    "# sub_train.shape\n",
    "\n",
    "# print(\"Processing Start\")\n",
    "# inter_table = []\n",
    "# for user, item, time in zip(train_data.user, train_data.item, train_data.time):\n",
    "#     uid, iid = userid_2_index[user], itemid_2_index[item]\n",
    "#     # tval = int(time.mktime(datetime.datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "#     inter_table.append( [uid, iid, time] )\n",
    "\n",
    "# print(\"Processing Complete\")\n",
    "\n",
    "print(\"Dump Start\")\n",
    "# 데이터 설정 파일 저장\n",
    "with open(yamlfile, \"w\") as f:\n",
    "    f.write(yamldata) \n",
    "\n",
    "# 데이터 파일 저장\n",
    "train_data.to_csv(os.path.join(outpath,\"train_data.inter\"),sep='\\t',index=False)\n",
    "user_data.to_csv(os.path.join(outpath,\"train_data.user\"),sep='\\t',index=False)\n",
    "item_data.to_csv(os.path.join(outpath,\"train_data.item\"),sep='\\t',index=False)\n",
    "# with open(outfile, \"w\") as f:\n",
    "#     # write header\n",
    "#     f.write(\"user_id:token\\titem_id:token\\ttimestamp:float\\n\")\n",
    "#     for row in inter_table:\n",
    "#         f.write(\"\\t\".join([str(x) for x in row])+\"\\n\")\n",
    "\n",
    "print(\"Dump Complete\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf654e50",
   "metadata": {},
   "source": [
    "### 로거 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "448113f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac5c55e3",
   "metadata": {},
   "source": [
    "### 설정 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c21f27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Dec 01:35    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/train_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 1\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'user': ['user_id'], 'item': ['item_id', 'year', 'writer', 'title', 'genre', 'director']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "fields = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configurations initialization\n",
    "config = Config(model='FFM', dataset=\"train_data\", config_file_list=[f'train_data.yaml'])\n",
    "config['epochs'] = 1\n",
    "config['show_progress'] = False\n",
    "config['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "\n",
    "logger.info(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a62100b4",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd284775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Dec 01:36    INFO  train_data\n",
      "The number of users: 31361\n",
      "Average actions of users: 148.54269770408163\n",
      "The number of items: 4968\n",
      "Average actions of items: 937.8496074088987\n",
      "The number of inters: 4658299\n",
      "The sparsity of the dataset: 97.01010545165151%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director']\n",
      "23 Dec 01:36    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "23 Dec 01:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# dataset filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa7da7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 99.86195790816326\n",
       "\u001b[1;34mThe number of items\u001b[0m: 4968\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 630.4954701026777\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 3131671\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 97.98996027302648%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 24.340369897959185\n",
       "\u001b[1;34mThe number of items\u001b[0m: 4968\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 153.67706865311052\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 763314\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.51007258931251%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 24.340369897959185\n",
       "\u001b[1;34mThe number of items\u001b[0m: 4968\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 153.67706865311052\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 763314\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.51007258931251%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset\n",
    "valid_data.dataset\n",
    "test_data.dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39da2a0e",
   "metadata": {},
   "source": [
    "### 모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419bdaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Dec 01:36    INFO  FFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(44399, 10)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(44399, 1)\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (ffm): FieldAwareFactorizationMachine(\n",
      "    (token_embeddings): ModuleList(\n",
      "      (0): Embedding(44399, 10)\n",
      "      (1): Embedding(44399, 10)\n",
      "      (2): Embedding(44399, 10)\n",
      "      (3): Embedding(44399, 10)\n",
      "      (4): Embedding(44399, 10)\n",
      "      (5): Embedding(44399, 10)\n",
      "    )\n",
      "  )\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 3152330\n"
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "model = FFM(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c05bfd1e",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bb1b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Dec 01:36    INFO  epoch 0 training [time: 32.97s, train loss: 1301.5134]\n",
      "23 Dec 01:38    INFO  epoch 0 evaluating [time: 101.75s, valid_score: 0.085600]\n",
      "23 Dec 01:38    INFO  valid result: \n",
      "recall@10 : 0.0856    mrr@10 : 0.3732    ndcg@10 : 0.1844    hit@10 : 0.7547    precision@10 : 0.1729    map@10 : 0.0872\n",
      "23 Dec 01:38    INFO  Saving current: saved/FFM-Dec-23-2022_01-36-21.pth\n"
     ]
    }
   ],
   "source": [
    "# trainer loading and initialization\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data, valid_data, saved=True, show_progress=config['show_progress']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baf0ea34",
   "metadata": {},
   "source": [
    "### 학습 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40d5e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Dec 01:38    INFO  Loading model structure and parameters from saved/FFM-Dec-23-2022_01-36-21.pth\n",
      "23 Dec 01:40    INFO  best valid : OrderedDict([('recall@10', 0.0856), ('mrr@10', 0.3732), ('ndcg@10', 0.1844), ('hit@10', 0.7547), ('precision@10', 0.1729), ('map@10', 0.0872)])\n",
      "23 Dec 01:40    INFO  test result: OrderedDict([('recall@10', 0.1017), ('mrr@10', 0.4477), ('ndcg@10', 0.2376), ('hit@10', 0.7799), ('precision@10', 0.2175), ('map@10', 0.1308)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"best_valid_score\": 0.0856,\n",
      "    \"valid_score_bigger\": true,\n",
      "    \"best_valid_result\": {\n",
      "        \"recall@10\": 0.0856,\n",
      "        \"mrr@10\": 0.3732,\n",
      "        \"ndcg@10\": 0.1844,\n",
      "        \"hit@10\": 0.7547,\n",
      "        \"precision@10\": 0.1729,\n",
      "        \"map@10\": 0.0872\n",
      "    },\n",
      "    \"test_result\": {\n",
      "        \"recall@10\": 0.1017,\n",
      "        \"mrr@10\": 0.4477,\n",
      "        \"ndcg@10\": 0.2376,\n",
      "        \"hit@10\": 0.7799,\n",
      "        \"precision@10\": 0.2175,\n",
      "        \"map@10\": 0.1308\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data, load_best_model=\"True\", show_progress=config['show_progress'])\n",
    "\n",
    "logger.info(set_color('best valid ', 'yellow') + f': {best_valid_result}')\n",
    "logger.info(set_color('test result', 'yellow') + f': {test_result}')\n",
    "\n",
    "result = {\n",
    "    'best_valid_score': best_valid_score,\n",
    "    'valid_score_bigger': config['valid_metric_bigger'],\n",
    "    'best_valid_result': best_valid_result,\n",
    "    'test_result': test_result\n",
    "}\n",
    "\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fefa4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Dec 01:41    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/train_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 1\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'user': ['user_id'], 'item': ['item_id', 'year', 'writer', 'title', 'genre', 'director']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "fields = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "23 Dec 01:42    INFO  train_data\n",
      "The number of users: 31361\n",
      "Average actions of users: 148.54269770408163\n",
      "The number of items: 4968\n",
      "Average actions of items: 937.8496074088987\n",
      "The number of inters: 4658299\n",
      "The sparsity of the dataset: 97.01010545165151%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director']\n",
      "23 Dec 01:42    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "23 Dec 01:42    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model_path='saved/FFM-Dec-23-2022_01-36-21.pth'\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d96a06f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c01e26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/245 [00:00<?, ?it/s]:  24%|██▍       | 60/245 [00:01<00:03, 59.52it/s]:  49%|████▉     | 120/245 [00:02<00:02, 59.07it/s]:  73%|███████▎  | 180/245 [00:03<00:01, 58.94it/s]:  98%|█████████▊| 239/245 [00:04<00:00, 58.71it/s]: 100%|██████████| 245/245 [00:04<00:00, 58.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from recbole.utils.case_study import full_sort_topk\n",
    "\n",
    "user_id = config['USER_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "all_user_list = torch.arange(1, len(user_id2token)).view(-1,128)\n",
    "\n",
    "device = config.final_config_dict['device']\n",
    "\n",
    "tbar = tqdm(all_user_list, desc=set_color(f\"Inference\", 'pink'), leave=True, mininterval=1)\n",
    "\n",
    "pred_list = None\n",
    "user_list = []\n",
    "for data in tbar:\n",
    "    batch_pred_list = full_sort_topk(data, model, test_data, 10, device=device)[1]\n",
    "    batch_pred_list = batch_pred_list.clone().detach().cpu().numpy()\n",
    "    if pred_list is None:\n",
    "        pred_list = batch_pred_list\n",
    "        user_list = data.numpy()\n",
    "    else:\n",
    "        pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "        user_list = np.append(\n",
    "            user_list, data.numpy(), axis=0\n",
    "        )\n",
    "tbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8283509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user별 item 추천 결과 하나로 합쳐주기\n",
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    for item in pred:\n",
    "        result.append((int(index_2_userid[user-1]), int(index_2_itemid[item])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7bed700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference done!\n"
     ]
    }
   ],
   "source": [
    "# submission file 제작하기\n",
    "sub = pd.DataFrame(result, columns=[\"user\", \"item\"])\n",
    "sub.to_csv(\n",
    "    \"submission_ffm.csv\", index=False\n",
    ")\n",
    "print('inference done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3d4ebc8f5be3b9760b7b8c89820e25f6cc4c8c3873d1ecd46134e38c918e05a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
