{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd73963",
   "metadata": {},
   "source": [
    "# FMM Recbole 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e884e8",
   "metadata": {},
   "source": [
    "### Recbole 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f451253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0037a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656860e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\"\n",
    "\n",
    "from logging import getLogger\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from recbole.model.context_aware_recommender.ffm import FFM\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.utils import init_logger, get_trainer, init_seed, set_color, get_model\n",
    "from recbole.quick_start.quick_start import load_data_and_model\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import ndcg_score, recall_score\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a025e",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf1eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/opt/ml/input/data/train/train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eeda3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5154471 entries, 0 to 5154470\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   user    int64\n",
      " 1   item    int64\n",
      " 2   time    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 118.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754874f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/opt/ml/input/data/train'\n",
    "year_data = pd.read_csv(os.path.join(data_path, 'years.tsv'), sep='\\t')\n",
    "writer_data = pd.read_csv(os.path.join(data_path, 'writers.tsv'), sep='\\t')\n",
    "title_data = pd.read_csv(os.path.join(data_path, 'titles.tsv'), sep='\\t')\n",
    "genre_data = pd.read_csv(os.path.join(data_path, 'genres.tsv'), sep='\\t')\n",
    "director_data = pd.read_csv(os.path.join(data_path, 'directors.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80736508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(train_df, year_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, writer_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, title_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, genre_data.drop_duplicates(subset=['item']), on='item', how='inner')\n",
    "df_merge = pd.merge(df_merge, director_data.drop_duplicates(subset=['item']), on='item', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0041c47a-d300-4d6e-a152-3bab72c710ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.read_csv('./uitgyt.csv')\n",
    "director_data = pd.read_csv('./director_fe.csv')\n",
    "writer_data = pd.read_csv('./writer_fe.csv')\n",
    "df_merge = pd.merge(df_merge, director_data, on='item', how='left')\n",
    "df_merge = pd.merge(df_merge, writer_data, on='item', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8cf5b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge.sort_values('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1660352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>time</th>\n",
       "      <th>genre_embedding</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>director_info</th>\n",
       "      <th>writer_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "      <td>-0.009958</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Planet of the Apes (2001)</td>\n",
       "      <td>2859.444444</td>\n",
       "      <td>4146.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>11</td>\n",
       "      <td>8640</td>\n",
       "      <td>1230856739</td>\n",
       "      <td>-0.010216</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>King Arthur (2004)</td>\n",
       "      <td>704.666667</td>\n",
       "      <td>8310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>11</td>\n",
       "      <td>8907</td>\n",
       "      <td>1230856729</td>\n",
       "      <td>-0.010698</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Shark Tale (2004)</td>\n",
       "      <td>9518.666667</td>\n",
       "      <td>28810.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>11</td>\n",
       "      <td>8965</td>\n",
       "      <td>1230856675</td>\n",
       "      <td>-0.010338</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Polar Express, The (2004)</td>\n",
       "      <td>3960.875000</td>\n",
       "      <td>5677.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>11</td>\n",
       "      <td>36401</td>\n",
       "      <td>1230856670</td>\n",
       "      <td>-0.010524</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Brothers Grimm, The (2005)</td>\n",
       "      <td>4461.615385</td>\n",
       "      <td>1339.923077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user   item        time  genre_embedding    year  \\\n",
       "0      11   4643  1230782529        -0.009958  2001.0   \n",
       "255    11   8640  1230856739        -0.010216  2004.0   \n",
       "254    11   8907  1230856729        -0.010698  2004.0   \n",
       "253    11   8965  1230856675        -0.010338  2004.0   \n",
       "252    11  36401  1230856670        -0.010524  2005.0   \n",
       "\n",
       "                          title  director_info   writer_info  \n",
       "0     Planet of the Apes (2001)    2859.444444   4146.333333  \n",
       "255          King Arthur (2004)     704.666667   8310.000000  \n",
       "254           Shark Tale (2004)    9518.666667  28810.000000  \n",
       "253   Polar Express, The (2004)    3960.875000   5677.444444  \n",
       "252  Brothers Grimm, The (2005)    4461.615385   1339.923077  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eaa10731",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_merge[['user', 'item', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "940e39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = df_merge[['user']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d7b2c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = df_merge[['item', 'year', 'writer_info', 'title', 'genre_embedding', 'director_info']]#.drop_duplicates(subset=['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd414cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5154471 entries, 0 to 5154470\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   user    int64\n",
      " 1   item    int64\n",
      " 2   time    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 157.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b31ea219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_user : 31360\n",
      "n_item : 6807\n"
     ]
    }
   ],
   "source": [
    "userid, itemid = list(set(train_data.user)), list(set(train_data.item))\n",
    "n_user, n_item = len(userid), len(itemid)\n",
    "print(f'n_user : {n_user}')\n",
    "print(f'n_item : {n_item}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f7e24",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17ee70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d043e6eb",
   "metadata": {},
   "source": [
    "### 데이터 파일 변환\n",
    "\n",
    "기존 데이터 파일을 Recbole 데이터 파일로 변환시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd4f31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid, itemid = sorted(userid), sorted(itemid)\n",
    "n_user, n_item = len(userid), len(itemid)\n",
    "\n",
    "userid_2_index = {v:i for i,v in enumerate(userid)}\n",
    "itemid_2_index = {v:i for i,v in enumerate(itemid)}\n",
    "index_2_userid = {i:v for i,v in enumerate(userid)}\n",
    "index_2_itemid = {i:v for i,v in enumerate(itemid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "921af69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yamldata = \"\"\"\n",
    "field_separator: \"\\t\"\n",
    "USER_ID_FIELD: user_id\n",
    "ITEM_ID_FIELD: item_id\n",
    "TIME_FIELD: timestamp\n",
    "\n",
    "load_col:\n",
    "    inter: [user_id, item_id, timestamp]\n",
    "    user: [user_id]\n",
    "    item: [item_id, year, writer, title, genre, director]\n",
    "\n",
    "train_neg_sample_args:\n",
    "    uniform: 1\n",
    "    \n",
    "eval_args:\n",
    "    split: {'RS': [4, 1, 1]}\n",
    "    group_by: user\n",
    "    order: RO\n",
    "    mode: full\n",
    "metrics: ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
    "topk: 10\n",
    "valid_metric: Recall@10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6b7236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27941/1297655130.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.user = train_data.user.map(userid_2_index)\n",
      "/tmp/ipykernel_27941/1297655130.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.item = train_data.item.map(itemid_2_index)\n",
      "/tmp/ipykernel_27941/1297655130.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_data.user = user_data.user.map(userid_2_index)\n",
      "/tmp/ipykernel_27941/1297655130.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  item_data.item = item_data.item.map(itemid_2_index)\n"
     ]
    }
   ],
   "source": [
    "train_data.user = train_data.user.map(userid_2_index)\n",
    "train_data.item = train_data.item.map(itemid_2_index)\n",
    "\n",
    "user_data.user = user_data.user.map(userid_2_index)\n",
    "item_data.item = item_data.item.map(itemid_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dd5f3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns=['user_id:token', 'item_id:token', 'timestamp:float']\n",
    "user_data.columns=['user_id:token']\n",
    "item_data.columns=['item_id:token', 'year:token', 'writer:token', 'title:token_seq', 'genre:token', 'director:token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f344922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Complete\n"
     ]
    }
   ],
   "source": [
    "outpath = f\"dataset/train_data\"\n",
    "# outfile = f\"dataset/train_data/train_data.inter\"\n",
    "yamlfile = f\"train_data.yaml\"\n",
    "\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "# sub_train=train.groupby(\"user\").sample(n=10, random_state=SEED)\n",
    "# sub_train.shape\n",
    "\n",
    "# print(\"Processing Start\")\n",
    "# inter_table = []\n",
    "# for user, item, time in zip(train_data.user, train_data.item, train_data.time):\n",
    "#     uid, iid = userid_2_index[user], itemid_2_index[item]\n",
    "#     # tval = int(time.mktime(datetime.datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\").timetuple()))\n",
    "#     inter_table.append( [uid, iid, time] )\n",
    "\n",
    "# print(\"Processing Complete\")\n",
    "\n",
    "print(\"Dump Start\")\n",
    "# 데이터 설정 파일 저장\n",
    "with open(yamlfile, \"w\") as f:\n",
    "    f.write(yamldata) \n",
    "\n",
    "# 데이터 파일 저장\n",
    "train_data.to_csv(os.path.join(outpath,\"train_data.inter\"),sep='\\t',index=False)\n",
    "user_data.to_csv(os.path.join(outpath,\"train_data.user\"),sep='\\t',index=False)\n",
    "item_data.to_csv(os.path.join(outpath,\"train_data.item\"),sep='\\t',index=False)\n",
    "# with open(outfile, \"w\") as f:\n",
    "#     # write header\n",
    "#     f.write(\"user_id:token\\titem_id:token\\ttimestamp:float\\n\")\n",
    "#     for row in inter_table:\n",
    "#         f.write(\"\\t\".join([str(x) for x in row])+\"\\n\")\n",
    "\n",
    "print(\"Dump Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf654e50",
   "metadata": {},
   "source": [
    "### 로거 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "448113f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c55e3",
   "metadata": {},
   "source": [
    "### 설정 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c21f27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 Dec 14:10    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/train_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 1\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'user': ['user_id'], 'item': ['item_id', 'year', 'writer', 'title', 'genre', 'director']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "fields = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configurations initialization\n",
    "config = Config(model='FFM', dataset=\"train_data\", config_file_list=[f'train_data.yaml'])\n",
    "config['epochs'] = 1\n",
    "config['show_progress'] = False\n",
    "config['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62100b4",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd284775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 Dec 14:12    INFO  train_data\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director']\n",
      "26 Dec 14:12    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "26 Dec 14:12    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# dataset filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa7da7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 110.4156568877551\n",
       "\u001b[1;34mThe number of items\u001b[0m: 6808\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 508.68738063757894\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 3462635\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 98.37820011614866%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 26.974426020408163\n",
       "\u001b[1;34mThe number of items\u001b[0m: 6808\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 124.29003820158684\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 845918\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.60379603563536%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;35mtrain_data\u001b[0m\n",
       "\u001b[1;34mThe number of users\u001b[0m: 31361\n",
       "\u001b[1;34mAverage actions of users\u001b[0m: 26.974426020408163\n",
       "\u001b[1;34mThe number of items\u001b[0m: 6808\n",
       "\u001b[1;34mAverage actions of items\u001b[0m: 124.27177905097693\n",
       "\u001b[1;34mThe number of inters\u001b[0m: 845918\n",
       "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.60379603563536%\n",
       "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director', 'label']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset\n",
    "valid_data.dataset\n",
    "test_data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da2a0e",
   "metadata": {},
   "source": [
    "### 모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "419bdaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 Dec 14:12    INFO  FFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(42227, 10)\n",
      "  )\n",
      "  (token_seq_embedding_table): ModuleList(\n",
      "    (0): Embedding(9166, 10)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(42227, 1)\n",
      "    )\n",
      "    (token_seq_embedding_table): ModuleList(\n",
      "      (0): Embedding(9166, 1)\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (ffm): FieldAwareFactorizationMachine(\n",
      "    (token_embeddings): ModuleList(\n",
      "      (0): Embedding(42227, 10)\n",
      "      (1): Embedding(42227, 10)\n",
      "      (2): Embedding(42227, 10)\n",
      "      (3): Embedding(42227, 10)\n",
      "      (4): Embedding(42227, 10)\n",
      "      (5): Embedding(42227, 10)\n",
      "      (6): Embedding(42227, 10)\n",
      "    )\n",
      "    (token_seq_embeddings): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (2): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (3): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (4): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (5): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "      (6): ModuleList(\n",
      "        (0): Embedding(9166, 10)\n",
      "        (1): Embedding(9166, 10)\n",
      "        (2): Embedding(9166, 10)\n",
      "        (3): Embedding(9166, 10)\n",
      "        (4): Embedding(9166, 10)\n",
      "        (5): Embedding(9166, 10)\n",
      "        (6): Embedding(9166, 10)\n",
      "      )\n",
      "    )\n",
      "    (token_seq_embedding): ModuleList(\n",
      "      (0): Embedding(9166, 10)\n",
      "      (1): Embedding(9166, 10)\n",
      "      (2): Embedding(9166, 10)\n",
      "      (3): Embedding(9166, 10)\n",
      "      (4): Embedding(9166, 10)\n",
      "      (5): Embedding(9166, 10)\n",
      "      (6): Embedding(9166, 10)\n",
      "    )\n",
      "  )\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 4162834\n"
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "model = FFM(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bfd1e",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7bb1b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 Dec 14:14    INFO  epoch 0 training [time: 74.21s, train loss: 1392.1670]\n",
      "26 Dec 14:19    INFO  epoch 0 evaluating [time: 290.06s, valid_score: 0.079700]\n",
      "26 Dec 14:19    INFO  valid result: \n",
      "recall@10 : 0.0797    mrr@10 : 0.3824    ndcg@10 : 0.1852    hit@10 : 0.7579    precision@10 : 0.1727    map@10 : 0.0876\n",
      "26 Dec 14:19    INFO  Saving current: saved/FFM-Dec-26-2022_14-12-59.pth\n"
     ]
    }
   ],
   "source": [
    "# trainer loading and initialization\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data, valid_data, saved=True, show_progress=config['show_progress']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0ea34",
   "metadata": {},
   "source": [
    "### 학습 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40d5e294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 Dec 14:19    INFO  Loading model structure and parameters from saved/FFM-Dec-26-2022_14-12-59.pth\n",
      "26 Dec 14:23    INFO  best valid : OrderedDict([('recall@10', 0.0797), ('mrr@10', 0.3824), ('ndcg@10', 0.1852), ('hit@10', 0.7579), ('precision@10', 0.1727), ('map@10', 0.0876)])\n",
      "26 Dec 14:23    INFO  test result: OrderedDict([('recall@10', 0.0943), ('mrr@10', 0.4578), ('ndcg@10', 0.2372), ('hit@10', 0.7858), ('precision@10', 0.2159), ('map@10', 0.13)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"best_valid_score\": 0.0797,\n",
      "    \"valid_score_bigger\": true,\n",
      "    \"best_valid_result\": {\n",
      "        \"recall@10\": 0.0797,\n",
      "        \"mrr@10\": 0.3824,\n",
      "        \"ndcg@10\": 0.1852,\n",
      "        \"hit@10\": 0.7579,\n",
      "        \"precision@10\": 0.1727,\n",
      "        \"map@10\": 0.0876\n",
      "    },\n",
      "    \"test_result\": {\n",
      "        \"recall@10\": 0.0943,\n",
      "        \"mrr@10\": 0.4578,\n",
      "        \"ndcg@10\": 0.2372,\n",
      "        \"hit@10\": 0.7858,\n",
      "        \"precision@10\": 0.2159,\n",
      "        \"map@10\": 0.13\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data, load_best_model=\"True\", show_progress=config['show_progress'])\n",
    "\n",
    "logger.info(set_color('best valid ', 'yellow') + f': {best_valid_result}')\n",
    "logger.info(set_color('test result', 'yellow') + f': {test_result}')\n",
    "\n",
    "result = {\n",
    "    'best_valid_score': best_valid_score,\n",
    "    'valid_score_bigger': config['valid_metric_bigger'],\n",
    "    'best_valid_result': best_valid_result,\n",
    "    'test_result': test_result\n",
    "}\n",
    "\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fefa4735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 Dec 14:23    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/train_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 1\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [10]\n",
      "valid_metric = Recall@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'user': ['user_id'], 'item': ['item_id', 'year', 'writer', 'title', 'genre', 'director']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 10\n",
      "fields = None\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "26 Dec 14:25    INFO  train_data\n",
      "The number of users: 31361\n",
      "Average actions of users: 164.36450892857144\n",
      "The number of items: 6808\n",
      "Average actions of items: 757.2309387395328\n",
      "The number of inters: 5154471\n",
      "The sparsity of the dataset: 97.58579218741939%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'year', 'writer', 'title', 'genre', 'director']\n",
      "26 Dec 14:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'uniform': 1, 'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "26 Dec 14:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model_path='saved/FFM-Dec-26-2022_14-12-59.pth'\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96a06f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c01e26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/245 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/recbole/utils/case_study.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  uid_series = torch.tensor(uid_series)\n",
      "Inference:   5%|▌         | 13/245 [00:01<00:19, 12.20it/s]:  11%|█         | 26/245 [00:02<00:17, 12.22it/s]:  16%|█▌        | 39/245 [00:03<00:16, 12.23it/s]:  21%|██        | 52/245 [00:04<00:15, 12.24it/s]:  27%|██▋       | 65/245 [00:05<00:14, 12.21it/s]:  32%|███▏      | 78/245 [00:06<00:13, 12.18it/s]:  37%|███▋      | 91/245 [00:07<00:12, 12.18it/s]:  42%|████▏     | 104/245 [00:08<00:11, 12.20it/s]:  48%|████▊     | 117/245 [00:09<00:10, 12.21it/s]:  53%|█████▎    | 130/245 [00:10<00:09, 12.20it/s]:  58%|█████▊    | 143/245 [00:11<00:08, 12.20it/s]:  64%|██████▎   | 156/245 [00:12<00:07, 12.20it/s]:  69%|██████▉   | 169/245 [00:13<00:06, 12.21it/s]:  74%|███████▍  | 182/245 [00:14<00:05, 12.21it/s]:  80%|███████▉  | 195/245 [00:15<00:04, 12.21it/s]:  85%|████████▍ | 208/245 [00:17<00:03, 12.21it/s]:  90%|█████████ | 221/245 [00:18<00:01, 12.21it/s]:  96%|█████████▌| 234/245 [00:19<00:00, 12.21it/s]: 100%|██████████| 245/245 [00:20<00:00, 12.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from recbole.utils.case_study import full_sort_topk\n",
    "\n",
    "user_id = config['USER_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "all_user_list = torch.arange(1, len(user_id2token)).view(-1,128)\n",
    "\n",
    "device = config.final_config_dict['device']\n",
    "\n",
    "tbar = tqdm(all_user_list, desc=set_color(f\"Inference\", 'pink'), leave=True, mininterval=1)\n",
    "\n",
    "pred_list = None\n",
    "user_list = []\n",
    "for data in tbar:\n",
    "    batch_pred_list = full_sort_topk(data, model, test_data, 10, device=device)[1]\n",
    "    batch_pred_list = batch_pred_list.clone().detach().cpu().numpy()\n",
    "    if pred_list is None:\n",
    "        pred_list = batch_pred_list\n",
    "        user_list = data.numpy()\n",
    "    else:\n",
    "        pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "        user_list = np.append(\n",
    "            user_list, data.numpy(), axis=0\n",
    "        )\n",
    "tbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e557d82c-188b-4f81-8fc3-beab136a4786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 106,  154,  297,  370,  354,  648,  358,  279,  412, 1406])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d8283509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user별 item 추천 결과 하나로 합쳐주기\n",
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    item_cnt = 0 # 10개가 되면 다음 유저로 이동\n",
    "    user = int(index_2_userid[user-1])\n",
    "    user_before = df_merge[df_merge['user'] == user]['item'].unique()\n",
    "    for item in pred:\n",
    "        item = int(index_2_itemid[item-1])\n",
    "        if item_cnt >= 10:\n",
    "            continue\n",
    "        if item not in user_before:\n",
    "            result.append((user, item))\n",
    "            item_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7bed700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference done!\n"
     ]
    }
   ],
   "source": [
    "# submission file 제작하기\n",
    "sub = pd.DataFrame(result, columns=[\"user\", \"item\"])\n",
    "sub.to_csv(\n",
    "    \"submission_ffm.csv\", index=False\n",
    ")\n",
    "print('inference done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ca3c0-0632-4ab2-a43c-dba5664530ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3d4ebc8f5be3b9760b7b8c89820e25f6cc4c8c3873d1ecd46134e38c918e05a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
