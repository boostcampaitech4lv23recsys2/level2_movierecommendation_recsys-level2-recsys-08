{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a99df8-8a8f-4946-b00c-3a44a91d1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# pip install transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "# 만약 주피터 노트북에서 아래와 관계있는 에러가 발생한다면\n",
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2934e197-9a25-4676-9531-1d11fb2bf5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('/opt/ml/input/data/train/train_ratings.csv') # user-item-time\n",
    "title_df = pd.read_csv('/opt/ml/input/data/train/titles.tsv', sep='\\t') # item-title\n",
    "year_df = pd.read_csv('/opt/ml/input/data/train/years.tsv', sep='\\t') # item-year\n",
    "director_df = pd.read_csv('/opt/ml/input/data/train/directors.tsv', sep='\\t') # item-director\n",
    "genre_name_df = pd.read_csv('/opt/ml/input/data/train/genres.tsv', sep='\\t') # item-genre(name)\n",
    "writer_df = pd.read_csv('/opt/ml/input/data/train/writers.tsv', sep='\\t') # item-writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdbdc183-6f46-44b8-bb89-fd1d9743ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dir_item_list = list(set(main_df['item']) - set(director_df['item']))\n",
    "no_dir_item_df = pd.DataFrame([x for x in zip(no_dir_item_list, ['nm0000000']*len(no_dir_item_list))])\n",
    "no_dir_item_df.columns=director_df.columns # 컬럼명 동일하게\n",
    "director_df = pd.concat([director_df, no_dir_item_df]) # 기존 director_df 뒤에 감독없는 영화 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34d197ec-3440-4924-b83f-4808fcca2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_direct = main_df.merge(director_df, how='left', on='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cc53ebb-9dcf-4ed1-9f0b-5973c205acdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>time</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "      <td>1230782529</td>\n",
       "      <td>nm0000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "      <td>1230782534</td>\n",
       "      <td>nm0812200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>1230782539</td>\n",
       "      <td>nm0002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>1230782542</td>\n",
       "      <td>nm0718627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "      <td>1230782563</td>\n",
       "      <td>nm0000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708948</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "      <td>1260209449</td>\n",
       "      <td>nm0757858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708949</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "      <td>1260209482</td>\n",
       "      <td>nm0601382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708950</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>1260209720</td>\n",
       "      <td>nm0004303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708951</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "      <td>1260209726</td>\n",
       "      <td>nm0003506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708952</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "      <td>1260209807</td>\n",
       "      <td>nm0000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5708953 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item        time   director\n",
       "0            11   4643  1230782529  nm0000318\n",
       "1            11    170  1230782534  nm0812200\n",
       "2            11    531  1230782539  nm0002140\n",
       "3            11    616  1230782542  nm0718627\n",
       "4            11   2140  1230782563  nm0000568\n",
       "...         ...    ...         ...        ...\n",
       "5708948  138493  44022  1260209449  nm0757858\n",
       "5708949  138493   4958  1260209482  nm0601382\n",
       "5708950  138493  68319  1260209720  nm0004303\n",
       "5708951  138493  40819  1260209726  nm0003506\n",
       "5708952  138493  27311  1260209807  nm0000000\n",
       "\n",
       "[5708953 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c958ec5c-0d76-4716-9038-219bce4f84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_direct = user_direct.drop(columns=['time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ebc599-7d7a-4556-ae3f-28ab440dd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_direct['rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d1b180b-5325-467c-b66d-75c2abc88536",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Nagetive instances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 695/31360 [00:01<00:59, 511.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u, u_items \u001b[38;5;129;01min\u001b[39;00m tqdm(user_group_dfs):\n\u001b[1;32m     10\u001b[0m     u_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(u_items)\n\u001b[0;32m---> 11\u001b[0m     i_user_neg_item \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu_items\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mu_items\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     i_user_neg_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m: [u]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(u_items), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m: i_user_neg_item, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(u_items)})\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_row \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32mmtrand.pyx:946\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 3. Negative instance 생성 : 각 유저별 true:false = 5:5, 20분정도 소요\n",
    "print(\"Create Nagetive instances\")\n",
    "# num_negative = 50\n",
    "user_group_dfs = list(user_direct.groupby('user')['item'])\n",
    "first_row = True\n",
    "user_neg_dfs = pd.DataFrame()\n",
    "items = set(user_direct.loc[:, 'item'])\n",
    "\n",
    "for u, u_items in tqdm(user_group_dfs):\n",
    "    u_items = set(u_items)\n",
    "    i_user_neg_item = np.random.choice(list(items - u_items), len(u_items), replace=False)\n",
    "    \n",
    "    i_user_neg_df = pd.DataFrame({'user': [u]*len(u_items), 'item': i_user_neg_item, 'rating': [0]*len(u_items)})\n",
    "    if first_row == True:\n",
    "        user_neg_dfs = i_user_neg_df\n",
    "        first_row = False\n",
    "    else:\n",
    "        user_neg_dfs = pd.concat([user_neg_dfs, i_user_neg_df], axis = 0, sort=False)\n",
    "\n",
    "user_direct = pd.concat([user_direct, user_neg_dfs], axis = 0, sort=False)\n",
    "user_direct = user_direct.drop(columns=['director'])\n",
    "user_direct = user_direct.merge(director_df, how='left', on='item')\n",
    "user_direct.to_csv(\"user_direct_neg_sampling.csv\", index=False)\n",
    "user_direct.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f816377e-3cc3-41a3-a827-08537fe27ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e42113f-7191-408f-b8e0-ea0b9c294d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_direct = pd.read_csv('./user_direct_neg_sampling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42273b92-59b2-40e2-af1f-01b3f2213b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5156dd83-0127-46a8-a6a0-1e775a91399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(basepath):\n",
    "#     path1 = os.path.join(basepath, \"train_data.csv\")\n",
    "#     path2 = os.path.join(basepath, \"test_data.csv\")\n",
    "#     data1 = pd.read_csv(path1)\n",
    "#     data2 = pd.read_csv(path2)\n",
    "\n",
    "#     data = pd.concat([data1, data2])\n",
    "#     data.drop_duplicates(\n",
    "#         subset=[\"userID\", \"assessmentItemID\"], keep=\"last\", inplace=True\n",
    "#     )\n",
    "\n",
    "    data = pd.read_csv(basepath)\n",
    "    return data\n",
    "\n",
    "\n",
    "def separate_data(data):\n",
    "    train_data = data[data.rating >= 0]\n",
    "    test_data = data[data.rating < 0]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def indexing_data(data):\n",
    "    userid, itemid = (\n",
    "        sorted(list(set(data.user))),\n",
    "        sorted(list(set(data.director))),\n",
    "    )\n",
    "    n_user, n_item = len(userid), len(itemid)\n",
    "\n",
    "    userid_2_index = {v: i for i, v in enumerate(userid)}\n",
    "    itemid_2_index = {v: i + n_user for i, v in enumerate(itemid)}\n",
    "    id_2_index = dict(userid_2_index, **itemid_2_index)\n",
    "\n",
    "    return id_2_index\n",
    "\n",
    "\n",
    "def process_data(data, id_2_index, device):\n",
    "    edge, label = [], []\n",
    "    for user, item, acode in zip(data.user, data.director, data.rating):\n",
    "        uid, iid = id_2_index[user], id_2_index[item]\n",
    "        edge.append([uid, iid])\n",
    "        label.append(acode)\n",
    "\n",
    "    edge = torch.LongTensor(edge).T\n",
    "    label = torch.LongTensor(label)\n",
    "\n",
    "    return dict(edge=edge.to(device), label=label.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ab7abc-bb3d-4d1d-8fea-e22214027723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(device, basepath, verbose=True, logger=None):\n",
    "    data = load_data(basepath)\n",
    "    train_data, test_data = separate_data(data)\n",
    "    id2index = indexing_data(data)\n",
    "    train_data_proc = process_data(train_data, id2index, device)\n",
    "    test_data_proc = process_data(test_data, id2index, device)\n",
    "\n",
    "    # if verbose:\n",
    "    #     print_data_stat(train_data, \"Train\", logger=logger)\n",
    "    #     print_data_stat(test_data, \"Test\", logger=logger)\n",
    "\n",
    "    return train_data_proc, test_data_proc, len(id2index), id2index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc12829-b649-41ab-bdef-ae66820658d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32675/1332057831.py:44: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  edge = torch.LongTensor(edge).T\n"
     ]
    }
   ],
   "source": [
    "# data prepare\n",
    "train_data, test_data, n_node, edge_index = prepare_dataset(\n",
    "    device, './user_direct_neg_sampling.csv', verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca349b5-e8c5-46d9-89ab-c4034a2fadff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32701"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ea5a2-2cf5-45f6-aa71-83dec2300841",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, ModuleList\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "from torch_geometric.nn.conv import LGConv\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "\n",
    "\n",
    "class LightGCN(torch.nn.Module):\n",
    "    r\"\"\"The LightGCN model from the `\"LightGCN: Simplifying and Powering\n",
    "    Graph Convolution Network for Recommendation\"\n",
    "    <https://arxiv.org/abs/2002.02126>`_ paper.\n",
    "\n",
    "    :class:`~torch_geometric.nn.models.LightGCN` learns embeddings by linearly\n",
    "    propagating them on the underlying graph, and uses the weighted sum of the\n",
    "    embeddings learned at all layers as the final embedding\n",
    "\n",
    "    .. math::\n",
    "        \\textbf{x}_i = \\sum_{l=0}^{L} \\alpha_l \\textbf{x}^{(l)}_i,\n",
    "\n",
    "    where each layer's embedding is computed as\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{(l+1)}_i = \\sum_{j \\in \\mathcal{N}(i)}\n",
    "        \\frac{1}{\\sqrt{\\deg(i)\\deg(j)}}\\mathbf{x}^{(l)}_j.\n",
    "\n",
    "    Two prediction heads and trainign objectives are provided:\n",
    "    **link prediction** (via\n",
    "    :meth:`~torch_geometric.nn.models.LightGCN.link_pred_loss` and\n",
    "    :meth:`~torch_geometric.nn.models.LightGCN.predict_link`) and\n",
    "    **recommendation** (via\n",
    "    :meth:`~torch_geometric.nn.models.LightGCN.recommendation_loss` and\n",
    "    :meth:`~torch_geometric.nn.models.LightGCN.recommend`).\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        Embeddings are propagated according to the graph connectivity specified\n",
    "        by :obj:`edge_index` while rankings or link probabilities are computed\n",
    "        according to the edges specified by :obj:`edge_label_index`.\n",
    "\n",
    "    Args:\n",
    "        num_nodes (int): The number of nodes in the graph.\n",
    "        embedding_dim (int): The dimensionality of node embeddings.\n",
    "        num_layers (int): The number of\n",
    "            :class:`~torch_geometric.nn.conv.LGConv` layers.\n",
    "        alpha (float or Tensor, optional): The scalar or vector specifying the\n",
    "            re-weighting coefficients for aggregating the final embedding.\n",
    "            If set to :obj:`None`, the uniform initialization of\n",
    "            :obj:`1 / (num_layers + 1)` is used. (default: :obj:`None`)\n",
    "        **kwargs (optional): Additional arguments of the underlying\n",
    "            :class:`~torch_geometric.nn.conv.LGConv` layers.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes: int,\n",
    "        embedding_dim: int,\n",
    "        num_layers: int,\n",
    "        alpha: Optional[Union[float, Tensor]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        if alpha is None:\n",
    "            alpha = 1. / (num_layers + 1)\n",
    "\n",
    "        if isinstance(alpha, Tensor):\n",
    "            assert alpha.size(0) == num_layers + 1\n",
    "        else:\n",
    "            alpha = torch.tensor([alpha] * (num_layers + 1))\n",
    "        self.register_buffer('alpha', alpha)\n",
    "\n",
    "        self.embedding = Embedding(num_nodes, embedding_dim)\n",
    "        self.convs = ModuleList([LGConv(**kwargs) for _ in range(num_layers)])\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "\n",
    "def get_embedding(self, edge_index: Adj) -> Tensor:\n",
    "        x = self.embedding.weight\n",
    "        out = x * self.alpha[0]\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            out = out + x * self.alpha[i + 1]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def forward(self, edge_index: Adj,\n",
    "                edge_label_index: OptTensor = None) -> Tensor:\n",
    "        r\"\"\"Computes rankings for pairs of nodes.\n",
    "\n",
    "        Args:\n",
    "            edge_index (Tensor or SparseTensor): Edge tensor specifying the\n",
    "                connectivity of the graph.\n",
    "            edge_label_index (Tensor, optional): Edge tensor specifying the\n",
    "                node pairs for which to compute rankings or probabilities.\n",
    "                If :obj:`edge_label_index` is set to :obj:`None`, all edges in\n",
    "                :obj:`edge_index` will be used instead. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        if edge_label_index is None:\n",
    "            if isinstance(edge_index, SparseTensor):\n",
    "                edge_label_index = torch.stack(edge_index.coo()[:2], dim=0)\n",
    "            else:\n",
    "                edge_label_index = edge_index\n",
    "\n",
    "        out = self.get_embedding(edge_index)\n",
    "\n",
    "        out_src = out[edge_label_index[0]]\n",
    "        out_dst = out[edge_label_index[1]]\n",
    "        return (out_src * out_dst).sum(dim=-1)\n",
    "\n",
    "\n",
    "def predict_link(self, edge_index: Adj, edge_label_index: OptTensor = None,\n",
    "                     prob: bool = False) -> Tensor:\n",
    "        r\"\"\"Predict links between nodes specified in :obj:`edge_label_index`.\n",
    "\n",
    "        Args:\n",
    "            prob (bool): Whether probabilities should be returned. (default:\n",
    "                :obj:`False`)\n",
    "        \"\"\"\n",
    "        pred = self(edge_index, edge_label_index).sigmoid()\n",
    "        return pred if prob else pred.round()\n",
    "\n",
    "\n",
    "def recommend(self, edge_index: Adj, src_index: OptTensor = None,\n",
    "                  dst_index: OptTensor = None, k: int = 1) -> Tensor:\n",
    "        r\"\"\"Get top-:math:`k` recommendations for nodes in :obj:`src_index`.\n",
    "\n",
    "        Args:\n",
    "            src_index (Tensor, optional): Node indices for which\n",
    "                recommendations should be generated.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            dst_index (Tensor, optional): Node indices which represent the\n",
    "                possible recommendation choices.\n",
    "                If set to :obj:`None`, all nodes will be used.\n",
    "                (default: :obj:`None`)\n",
    "            k (int, optional): Number of recommendations. (default: :obj:`1`)\n",
    "        \"\"\"\n",
    "        out_src = out_dst = self.get_embedding(edge_index)\n",
    "\n",
    "        if src_index is not None:\n",
    "            out_src = out_src[src_index]\n",
    "\n",
    "        if dst_index is not None:\n",
    "            out_dst = out_dst[dst_index]\n",
    "\n",
    "        pred = out_src @ out_dst.t()\n",
    "        top_index = pred.topk(k, dim=-1).indices\n",
    "\n",
    "        if dst_index is not None:  # Map local top-indices to original indices.\n",
    "            top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "        return top_index\n",
    "\n",
    "\n",
    "def link_pred_loss(self, pred: Tensor, edge_label: Tensor,\n",
    "                       **kwargs) -> Tensor:\n",
    "        r\"\"\"Computes the model loss for a link prediction objective via the\n",
    "        :class:`torch.nn.BCEWithLogitsLoss`.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): The predictions.\n",
    "            edge_label (Tensor): The ground-truth edge labels.\n",
    "            **kwargs (optional): Additional arguments of the underlying\n",
    "                :class:`torch.nn.BCEWithLogitsLoss` loss function.\n",
    "        \"\"\"\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss(**kwargs)\n",
    "        return loss_fn(pred, edge_label.to(pred.dtype))\n",
    "\n",
    "\n",
    "def recommendation_loss(self, pos_edge_rank: Tensor, neg_edge_rank: Tensor,\n",
    "                            lambda_reg: float = 1e-4, **kwargs) -> Tensor:\n",
    "        r\"\"\"Computes the model loss for a ranking objective via the Bayesian\n",
    "        Personalized Ranking (BPR) loss.\n",
    "\n",
    "        .. note::\n",
    "\n",
    "            The i-th entry in the :obj:`pos_edge_rank` vector and i-th entry\n",
    "            in the :obj:`neg_edge_rank` entry must correspond to ranks of\n",
    "            positive and negative edges of the same entity (*e.g.*, user).\n",
    "\n",
    "        Args:\n",
    "            pos_edge_rank (Tensor): Positive edge rankings.\n",
    "            neg_edge_rank (Tensor): Negative edge rankings.\n",
    "            lambda_reg (int, optional): The :math:`L_2` regularization strength\n",
    "                of the Bayesian Personalized Ranking (BPR) loss.\n",
    "                (default: 1e-4)\n",
    "            **kwargs (optional): Additional arguments of the underlying\n",
    "                :class:`torch_geometric.nn.models.lightgcn.BPRLoss` loss\n",
    "                function.\n",
    "        \"\"\"\n",
    "        loss_fn = BPRLoss(lambda_reg, **kwargs)\n",
    "        return loss_fn(pos_edge_rank, neg_edge_rank, self.embedding.weight)\n",
    "\n",
    "\n",
    "def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.num_nodes}, '\n",
    "                f'{self.embedding_dim}, num_layers={self.num_layers})')\n",
    "\n",
    "\n",
    "\n",
    "class BPRLoss(_Loss):\n",
    "    r\"\"\"The Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "    The BPR loss is a pairwise loss that encourages the prediction of an\n",
    "    observed entry to be higher than its unobserved counterparts\n",
    "    (see `here <https://arxiv.org/abs/2002.02126>`__).\n",
    "\n",
    "    .. math::\n",
    "        L_{\\text{BPR}} = - \\sum_{u=1}^{M} \\sum_{i \\in \\mathcal{N}_u}\n",
    "        \\sum_{j \\not\\in \\mathcal{N}_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})\n",
    "        + \\lambda \\vert\\vert \\textbf{x}^{(0)} \\vert\\vert^2\n",
    "\n",
    "    where :math:`lambda` controls the :math:`L_2` regularization strength.\n",
    "    We compute the mean BPR loss for simplicity.\n",
    "\n",
    "    Args:\n",
    "        lambda_reg (float, optional): The :math:`L_2` regularization strength\n",
    "            (default: 0).\n",
    "        **kwargs (optional): Additional arguments of the underlying\n",
    "            :class:`torch.nn.modules.loss._Loss` class.\n",
    "    \"\"\"\n",
    "    __constants__ = ['lambda_reg']\n",
    "    lambda_reg: float\n",
    "\n",
    "    def __init__(self, lambda_reg: float = 0, **kwargs) -> None:\n",
    "        super().__init__(None, None, \"sum\", **kwargs)\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, positives: Tensor, negatives: Tensor,\n",
    "                parameters: Tensor = None) -> Tensor:\n",
    "        r\"\"\"Compute the mean Bayesian Personalized Ranking (BPR) loss.\n",
    "\n",
    "        .. note::\n",
    "\n",
    "            The i-th entry in the :obj:`positives` vector and i-th entry\n",
    "            in the :obj:`negatives` entry should correspond to the same\n",
    "            entity (*.e.g*, user), as the BPR is a personalized ranking loss.\n",
    "\n",
    "        Args:\n",
    "            positives (Tensor): The vector of positive-pair rankings.\n",
    "            negatives (Tensor): The vector of negative-pair rankings.\n",
    "            parameters (Tensor, optional): The tensor of parameters which\n",
    "                should be used for :math:`L_2` regularization\n",
    "                (default: :obj:`None`).\n",
    "        \"\"\"\n",
    "        n_pairs = positives.size(0)\n",
    "        log_prob = F.logsigmoid(positives - negatives).mean()\n",
    "        regularization = 0\n",
    "\n",
    "        if self.lambda_reg != 0:\n",
    "            regularization = self.lambda_reg * parameters.norm(p=2).pow(2)\n",
    "\n",
    "        return (-log_prob + regularization) / n_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "258e8d19-aee5-4193-9b0e-16baeb2082b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html\n",
      "Collecting torch-sparse==0.6.13\n",
      "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.13-cp38-cp38-linux_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from torch-sparse==0.6.13) (1.8.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scipy->torch-sparse==0.6.13) (1.23.5)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!python -m pip install torch-sparse==0.6.13 -f https://pytorch-geometric.com/whl/torch-1.10.0+cu113.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a0c08e-fc09-481c-be1e-9dc2c2ada229",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: / \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "\\ ^C\n",
      "failed\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !conda install pyg -c pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470323e-4c84-4ba9-ad36-53928b923700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.models import LightGCN\n",
    "\n",
    "def build(itemnode, n_node, weight=None, logger=None, **kwargs):\n",
    "    model = LightGCN(n_node, **kwargs)\n",
    "    \n",
    "    # if itemnode != \"assessmentItemID\":\n",
    "    #     weight = \"/opt/ml/dkt_team/code/lightgcn/weight/\" + itemnode + \"_best_model.pt\"\n",
    "    # else :\n",
    "    #     weight = \"/opt/ml/dkt_team/code/lightgcn/weight/best_model.pt\"\n",
    "        \n",
    "    if weight:\n",
    "        if not os.path.isfile(weight):\n",
    "            logger.fatal(\"Model Weight File Not Exist\")\n",
    "        logger.info(\"Load model\")\n",
    "        state = torch.load(weight)[\"model\"]\n",
    "        model.load_state_dict(state)\n",
    "        return model\n",
    "    else:\n",
    "        logger.info(\"No load model\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7375e6c-051e-4f70-b5f7-3b712f24585f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torch_geometric) (4.51.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from torch_geometric) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch_geometric) (2.11.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torch_geometric) (2.24.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.8/site-packages (from torch_geometric) (3.0.7)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from torch_geometric) (1.2.0)\n",
      "Collecting psutil>=5.8.0\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch_geometric) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torch_geometric) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torch_geometric) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torch_geometric) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->torch_geometric) (3.0.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "Building wheels for collected packages: torch_geometric\n",
      "  Building wheel for torch_geometric (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch_geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773285 sha256=21f2ae9d2a095bb95fa5350730d6c4705dd2fb4c3325552d573daa9feb673e8b\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/b5/f0/b1/623215620977e23579933d227d42c0eb8db77489da26727c56\n",
      "Successfully built torch_geometric\n",
      "Installing collected packages: psutil, torch_geometric\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.7.2\n",
      "    Uninstalling psutil-5.7.2:\n",
      "      Successfully uninstalled psutil-5.7.2\n",
      "Successfully installed psutil-5.9.4 torch_geometric-2.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee12c10d-4765-4ee8-a990-fcc56e84548c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model build\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild\u001b[49m(\n\u001b[1;32m      3\u001b[0m     n_node,\n\u001b[1;32m      4\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      5\u001b[0m     num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m      6\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m,\n\u001b[1;32m      7\u001b[0m     logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build' is not defined"
     ]
    }
   ],
   "source": [
    "# model build\n",
    "model = build(\n",
    "    n_node,\n",
    "    embedding_dim=8,\n",
    "    num_layers=3,\n",
    "    alpha=0.005,\n",
    "    logger=None,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff1a23-fef3-4c58-b480-0ce81eff99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model train\n",
    "train(\n",
    "    model,\n",
    "    train_data,\n",
    "    n_epoch=20,\n",
    "    learning_rate=0.005,\n",
    "    use_wandb=False,\n",
    "    weight=\"./weight\",\n",
    "    # logger=logger.getChild(\"train\"),\n",
    ")\n",
    "logger.info(\"Task Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d61201-12be-43f4-ba5c-31abb7b0ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(CFG.output_dir):\n",
    "#     os.makedirs(CFG.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fb5f1-080f-43f1-a797-d668c6121ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = inference(model, test_data)#, logger=logger.getChild(\"infer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f79ba12-5936-465e-a30f-57b66647a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.detach().cpu().numpy()\n",
    "pd.DataFrame({\"prediction\": pred}).to_csv(\n",
    "        \"plus_test_submission.csv\", index_label=\"id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56bfb80-a690-4dc8-a3b8-68e8d1976b12",
   "metadata": {},
   "source": [
    "# 임베딩 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc6d16-0977-4485-8908-651187ef4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92899352-0169-4ba5-a2ca-2603dc2abc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bc3bd-ef37-41e2-bdda-543a6cffa87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32f72e-50da-42b1-8d33-18d2c8ff9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.get_embedding(train_data['edge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4312c2b-c44c-4918-a1d9-62bb16ba97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57509bbf-1a8d-4c0a-bd01-cfd27e4fd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37854f2d-cc5e-4803-a951-519aa4f46abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = embed[edge_index[0]]\n",
    "p2 = embed[edge_index['A060001001']]\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e8842-2f14-4f9b-b01e-c22838f3d94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24702f-efec-4e9d-a65d-81161a6ffad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
